# ğŸ¨ Real-time Background Remover vá»›i Apache Spark

<div align="center">

![Demo](gif/Recording%202026-01-06%20204846.gif)

**Há»‡ thá»‘ng xÃ³a phÃ´ng ná»n video real-time vá»›i Apache Spark & MediaPipe**

[![Apache Spark](https://img.shields.io/badge/Apache%20Spark-3.5.0-orange?style=flat-square&logo=apache-spark)](https://spark.apache.org/)
[![Python](https://img.shields.io/badge/Python-3.9+-blue?style=flat-square&logo=python)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?style=flat-square&logo=docker)](https://www.docker.com/)
[![MediaPipe](https://img.shields.io/badge/MediaPipe-AI-4285F4?style=flat-square)](https://google.github.io/mediapipe/)
[![Streamlit](https://img.shields.io/badge/Streamlit-WebRTC-FF4B4B?style=flat-square)](https://streamlit.io/)

</div>

---

## ğŸ‘¨â€ğŸ’» ThÃ´ng Tin Sinh ViÃªn

- **MÃ´n há»c:** IE212 - Big Data Technologies
- **Sinh viÃªn:** Tráº§n Nguyá»…n Äá»©c Trung
- **MSSV:** 23521687
- **Lá»›p:** IE212.P11
- **Há»c ká»³:** 1, NÄƒm há»c 2024-2025
- **GitHub:** [Trunguit1122](https://github.com/Trunguit1122)

---

## ğŸ“– Giá»›i Thiá»‡u Äá» TÃ i

### ğŸ¯ Má»¥c TiÃªu
XÃ¢y dá»±ng há»‡ thá»‘ng xá»­ lÃ½ video streaming real-time Ä‘á»ƒ loáº¡i bá» phÃ´ng ná»n, sá»­ dá»¥ng:
- **Apache Spark** Ä‘á»ƒ xá»­ lÃ½ phÃ¢n tÃ¡n cÃ¡c frame video
- **MediaPipe** Ä‘á»ƒ phÃ¢n Ä‘oáº¡n ngÆ°á»i vÃ  ná»n
- **Streamlit WebRTC** Ä‘á»ƒ capture vÃ  hiá»ƒn thá»‹ video tá»« webcam
- **TCP Socket** Ä‘á»ƒ streaming dá»¯ liá»‡u giá»¯a cÃ¡c thÃ nh pháº§n

### ğŸ† YÃªu Cáº§u BÃ i Táº­p
âœ… Stream video frames qua **TCP Socket**  
âœ… Xá»­ lÃ½ frames báº±ng **Apache Spark RDD**  
âœ… Hiá»ƒn thá»‹ káº¿t quáº£ real-time trÃªn **Web UI**  
âœ… Deploy há»‡ thá»‘ng báº±ng **Docker Compose**  

### ğŸ’¡ Ã TÆ°á»Ÿng Thá»±c Hiá»‡n
Há»‡ thá»‘ng gá»“m 3 thÃ nh pháº§n chÃ­nh:
1. **Streamlit WebRTC Client**: Capture video tá»« webcam, hiá»ƒn thá»‹ káº¿t quáº£
2. **TCP Socket Channel**: Stream frames giá»¯a client vÃ  server
3. **Spark Processing Server**: Nháº­n frames, xá»­ lÃ½ phÃ¢n tÃ¡n vá»›i Spark, tráº£ vá» káº¿t quáº£

---

## ğŸ—ï¸ Kiáº¿n TrÃºc Há»‡ Thá»‘ng

### SÆ¡ Äá»“ Tá»•ng Quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser        â”‚
â”‚   (Webcam)       â”‚  Streamlit WebRTC
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  Capture Video
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit App   â”‚  
â”‚  (Client)        â”‚  Encode frame â†’ JPEG bytes
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ TCP Socket
         â”‚ Port 9998
         â”‚ [Header: frame_id, size | Payload: JPEG data]
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Spark Stream    â”‚  
â”‚  Server          â”‚  TCP Server
â”‚  (Processing)    â”‚  
â”‚                  â”‚  1. Receive & decode frame
â”‚                  â”‚  2. Create Spark RDD: 
â”‚                  â”‚     sc.parallelize([frame])
â”‚                  â”‚  3. Process with Spark:
â”‚                  â”‚     rdd.map(remove_bg)
â”‚                  â”‚  4. Collect result
â”‚                  â”‚  5. Encode & send back
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Apache Spark    â”‚
â”‚  Cluster         â”‚
â”‚                  â”‚
â”‚  Master + 2      â”‚  MediaPipe Segmentation
â”‚  Workers         â”‚  Background Removal
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  Parallel Processing
```

### Luá»“ng Xá»­ LÃ½ Chi Tiáº¿t

1. ğŸ“· **Webcam** â†’ Streamlit WebRTC capture frame (30fps)
2. ğŸ”„ **Streamlit** â†’ Encode frame thÃ nh JPEG bytes
3. ğŸ“¦ **TCP Client** â†’ ÄÃ³ng gÃ³i packet vá»›i header: `[frame_id: 4 bytes][size: 4 bytes][data: N bytes]`
4. ğŸŒ **TCP Stream** â†’ Gá»­i qua socket Ä‘áº¿n Spark Server (port 9998)
5. ğŸ“¥ **Spark Server** â†’ Nháº­n vÃ  giáº£i mÃ£ packet thÃ nh numpy array
6. âš¡ **Spark RDD** â†’ `spark_context.parallelize([frame]).map(remove_background).collect()`
7. ğŸ¤– **MediaPipe** â†’ PhÃ¢n Ä‘oáº¡n ngÆ°á»i/ná»n, thay ná»n thÃ nh mÃ u xÃ¡m (192, 192, 192)
8. ğŸ“¤ **Response** â†’ Encode káº¿t quáº£ thÃ nh JPEG, gá»­i vá» client qua TCP
9. ğŸ–¥ï¸ **Display** â†’ Streamlit nháº­n vÃ  hiá»ƒn thá»‹ frame Ä‘Ã£ xá»­ lÃ½

---

## ğŸ“ Cáº¥u TrÃºc Project

```
Lab04-BackgroundRemover/
â”‚
â”œâ”€â”€ ğŸ app_realtime.py           # Streamlit WebRTC interface
â”œâ”€â”€ ğŸ spark_stream_server.py    # TCP Server + Spark processing
â”œâ”€â”€ ğŸ background_remover.py     # MediaPipe segmentation module
â”œâ”€â”€ ğŸ spark_processor.py        # Spark processor helper
â”‚
â”œâ”€â”€ ğŸ³ docker-compose.yml        # Orchestration: Spark + Services
â”œâ”€â”€ ğŸ³ Dockerfile                # Build image vá»›i Python dependencies
â”œâ”€â”€ ğŸ“¦ requirements.txt          # Python packages
â”œâ”€â”€ ğŸ“˜ README.md                 # Documentation
â”‚
â”œâ”€â”€ ğŸ“‚ models/
â”‚   â””â”€â”€ selfie_segmenter.tflite # MediaPipe AI model (segmentation)
â”‚
â””â”€â”€ ğŸ“‚ output_images/            # Saved processed frames
```

**Core Files:**
- `app_realtime.py`: Giao diá»‡n Streamlit vá»›i WebRTC, TCP client Ä‘á»ƒ gá»­i/nháº­n frames
- `spark_stream_server.py`: TCP server nháº­n frames, xá»­ lÃ½ báº±ng Spark RDD, tráº£ vá» káº¿t quáº£
- `background_remover.py`: Module AI xÃ³a ná»n vá»›i MediaPipe Selfie Segmentation
- `docker-compose.yml`: Deploy Spark cluster (1 master + 2 workers) + application

---

## ğŸš€ HÆ°á»›ng Dáº«n Cháº¡y Há»‡ Thá»‘ng

### YÃªu Cáº§u

- **Docker** vÃ  **Docker Compose** Ä‘Ã£ cÃ i Ä‘áº·t
- **4GB RAM** trá»Ÿ lÃªn (cho Spark cluster)
- **Webcam** Ä‘á»ƒ test real-time
- **Ports** kháº£ dá»¥ng: 7077, 8080, 8501, 9998

### CÃ i Äáº·t & Cháº¡y

#### BÆ°á»›c 1: Clone Repository

```bash
git clone https://github.com/Trunguit1122/Lab4-IE212.git
cd Lab4-IE212
```

#### BÆ°á»›c 2: Khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng

```bash
# Build vÃ  start táº¥t cáº£ services
docker-compose up -d --build

# Há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng khá»Ÿi Ä‘á»™ng:
# - Spark Master (port 7077, 8080)
# - Spark Worker 1 & 2
# - Spark Stream Server (port 9998)
# - Streamlit App (port 8501)
```

#### BÆ°á»›c 3: Truy cáº­p giao diá»‡n

```bash
# Má»Ÿ Streamlit Web UI
http://localhost:8501

# Má»Ÿ Spark Master UI (theo dÃµi jobs)
http://localhost:8080
```

#### BÆ°á»›c 4: Sá»­ dá»¥ng

1. Truy cáº­p `http://localhost:8501`
2. Cho phÃ©p trÃ¬nh duyá»‡t truy cáº­p webcam
3. Nháº¥n **START** Ä‘á»ƒ báº¯t Ä‘áº§u xá»­ lÃ½
4. Video sáº½ hiá»ƒn thá»‹ vá»›i ná»n Ä‘Ã£ Ä‘Æ°á»£c thay tháº¿ mÃ u xÃ¡m

### Kiá»ƒm Tra Logs

```bash
# Xem log Spark Stream Server
docker logs -f processing-background-remover

# Xem log Streamlit App
docker logs -f streamlit-background-remover

# Xem log Spark Master
docker logs -f spark-master
```

### Dá»«ng Há»‡ Thá»‘ng

```bash
# Stop táº¥t cáº£ containers
docker-compose down

# Stop vÃ  xÃ³a volumes
docker-compose down -v
```

---

## ğŸ”§ Chi Tiáº¿t Ká»¹ Thuáº­t

### 1ï¸âƒ£ Streamlit WebRTC Client (`app_realtime.py`)

**CÃ´ng nghá»‡:**
- `streamlit-webrtc` Ä‘á»ƒ capture video tá»« webcam
- `av` (PyAV) Ä‘á»ƒ xá»­ lÃ½ video frames
- Custom `VideoProcessor` káº¿ thá»«a `VideoProcessorBase`

**Workflow:**
```python
class SparkBackgroundRemover(VideoProcessorBase):
    def recv(self, frame):
        # 1. Convert WebRTC frame â†’ numpy array
        img = frame.to_ndarray(format="bgr24")
        
        # 2. Encode â†’ JPEG bytes
        _, buffer = cv2.imencode('.jpg', img, [cv2.IMWRITE_JPEG_QUALITY, 85])
        
        # 3. Send via TCP to Spark Server
        processed = self._send_to_spark_server(buffer.tobytes())
        
        # 4. Decode response & display
        return av.VideoFrame.from_ndarray(processed, format="bgr24")
```

**TCP Protocol:**
```python
# Client gá»­i:
struct.pack('!I', frame_id)    # 4 bytes: ID
struct.pack('!I', len(data))   # 4 bytes: size
data                            # N bytes: JPEG payload
```

### 2ï¸âƒ£ Spark Stream Server (`spark_stream_server.py`)

**Chá»©c nÄƒng chÃ­nh:**
- TCP Server láº¯ng nghe trÃªn port 9998
- Nháº­n frames tá»« client, giáº£i mÃ£ thÃ nh numpy array
- Sá»­ dá»¥ng Spark RDD Ä‘á»ƒ xá»­ lÃ½ phÃ¢n tÃ¡n
- Tráº£ káº¿t quáº£ vá» client

**Spark Processing:**
```python
# Khá»Ÿi táº¡o Spark Context
conf = SparkConf().setAppName("BackgroundRemover") \
                  .setMaster("spark://spark-master:7077")
sc = SparkContext(conf=conf)

# Xá»­ lÃ½ frame
def process_frame(frame_data):
    # 1. Create RDD tá»« frame
    rdd = sc.parallelize([frame_data])
    
    # 2. Map vá»›i background removal function
    results = rdd.map(lambda x: remove_background(x)).collect()
    
    # 3. Return processed frame
    return results[0]
```

**TCP Server:**
```python
def handle_client(conn):
    while True:
        # 1. Receive header (frame_id + size)
        header = conn.recv(8)
        frame_id, size = struct.unpack('!II', header)
        
        # 2. Receive payload (JPEG data)
        data = b''
        while len(data) < size:
            packet = conn.recv(min(8192, size - len(data)))
            data += packet
        
        # 3. Decode â†’ numpy array
        frame = cv2.imdecode(np.frombuffer(data, np.uint8), cv2.IMREAD_COLOR)
        
        # 4. Process with Spark
        processed = process_frame(frame)
        
        # 5. Encode & send back
        _, buffer = cv2.imencode('.jpg', processed)
        response = struct.pack('!I', len(buffer)) + buffer.tobytes()
        conn.sendall(response)
```

### 3ï¸âƒ£ Background Remover (`background_remover.py`)

**CÃ´ng nghá»‡:**
- **MediaPipe Selfie Segmentation** (Google Research)
- Model: `selfie_segmenter.tflite` (pretrained)
- Output: Segmentation mask (person vs background)

**Algorithm:**
```python
def remove_background(image, bg_color=(192, 192, 192)):
    # 1. MediaPipe segmentation
    results = segmenter.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    mask = results.segmentation_mask
    
    # 2. Threshold mask (person > 0.2)
    condition = mask > 0.2
    
    # 3. Create background color image
    bg_image = np.full(image.shape, bg_color, dtype=np.uint8)
    
    # 4. Composite: person = original, background = gray
    output = np.where(condition[:, :, np.newaxis], image, bg_image)
    
    return output
```

**Note:** Code gá»‘c cá»§a giáº£ng viÃªn cÃ³ logic Ä‘áº£o ngÆ°á»£c (personâ†’gray, bgâ†’original), nÃªn trong `spark_stream_server.py` cÃ³ invert láº¡i vá»›i NOT operator Ä‘á»ƒ Ä‘Ãºng yÃªu cáº§u.

---

## ğŸ“Š Services & Containers

| Service | Container Name | Image | Port | Resource |
|---------|---------------|-------|------|----------|
| **Spark Master** | spark-master | bitnami/spark:3.5.0 | 7077, 8080 | 1GB RAM |
| **Spark Worker 1** | spark-worker-1 | Custom Dockerfile | - | 2 cores, 2GB |
| **Spark Worker 2** | spark-worker-2 | Custom Dockerfile | - | 2 cores, 2GB |
| **Processing Server** | processing-background-remover | Custom Dockerfile | 9998 | 2GB RAM |
| **Streamlit App** | streamlit-background-remover | Custom Dockerfile | 8501 | 1GB RAM |

**Docker Compose Configuration:**
```yaml
services:
  spark-master:
    image: bitnami/spark:3.5.0
    ports: ["8080:8080", "7077:7077"]
    environment:
      - SPARK_MODE=master
    restart: unless-stopped

  spark-worker-1:
    build: .
    command: /opt/bitnami/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
      - MEDIAPIPE_DISABLE_GPU=1
    restart: unless-stopped

  processing-server:
    build: .
    command: python spark_stream_server.py
    ports: ["9998:9998"]
    depends_on: [spark-master, spark-worker-1, spark-worker-2]
    restart: unless-stopped

  streamlit-app:
    build: .
    command: streamlit run app_realtime.py --server.port=8501
    ports: ["8501:8501"]
    depends_on: [processing-server]
    restart: unless-stopped
```

---

## âš¡ Performance & Scalability

### ThÃ´ng Sá»‘ Äo ÄÆ°á»£c

- **Throughput:** ~15-20 frames/second vá»›i 2 workers
- **Latency:** ~50-100ms/frame (bao gá»“m network + processing)
- **GPU:** Disable (CPU-only vá»›i `MEDIAPIPE_DISABLE_GPU=1`)

### Kháº£ NÄƒng Má»Ÿ Rá»™ng

**TÄƒng sá»‘ workers:**
```yaml
# ThÃªm vÃ o docker-compose.yml
spark-worker-3:
  build: .
  command: /opt/bitnami/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
  environment:
    - SPARK_WORKER_CORES=2
    - SPARK_WORKER_MEMORY=2g
    - MEDIAPIPE_DISABLE_GPU=1
  restart: unless-stopped
```

**TÄƒng resource cho worker:**
```yaml
environment:
  - SPARK_WORKER_CORES=4      # TÄƒng cores
  - SPARK_WORKER_MEMORY=4g    # TÄƒng RAM
```

---

## ğŸ“ Kiáº¿n Thá»©c Ãp Dá»¥ng

### Big Data Concepts

âœ… **Streaming Data Processing**
- TCP Socket streaming giá»¯a cÃ¡c components
- Real-time data pipeline (capture â†’ process â†’ display)

âœ… **Distributed Computing vá»›i Apache Spark**
- Spark RDD (Resilient Distributed Dataset)
- Transformation: `parallelize()`, `map()`
- Action: `collect()`
- Cluster mode: Master + Multiple Workers

âœ… **Fault Tolerance**
- Docker restart policies: `unless-stopped`
- Spark automatic task retry khi worker fail

âœ… **Scalability**
- Horizontal scaling: ThÃªm workers Ä‘á»ƒ tÄƒng throughput
- Load balancing: Spark tá»± Ä‘á»™ng phÃ¢n phá»‘i tasks

### Technologies Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Frontend** | Streamlit WebRTC | Video capture & display |
| **Communication** | TCP Socket | Frame streaming protocol |
| **Processing** | Apache Spark | Distributed computing |
| **AI/ML** | MediaPipe | Selfie segmentation |
| **Container** | Docker Compose | Orchestration & deployment |
| **Language** | Python 3.9+ | Application runtime |

---

## ğŸ› Troubleshooting

### Container khÃ´ng start

```bash
# Xem logs chi tiáº¿t
docker-compose logs -f

# Restart specific service
docker-compose restart processing-server
```

### Port Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng

```bash
# Kiá»ƒm tra port
sudo lsof -i :8501
sudo lsof -i :9998

# Kill process cÅ©
sudo kill -9 <PID>

# Hoáº·c thay Ä‘á»•i port trong docker-compose.yml
```

### Connection refused

```bash
# Äáº£m báº£o processing server Ä‘Ã£ cháº¡y
docker ps | grep processing

# Check network connectivity giá»¯a containers
docker exec streamlit-background-remover ping processing-server
```

### Webcam khÃ´ng hoáº¡t Ä‘á»™ng

- Äáº£m báº£o browser há»— trá»£ WebRTC (Chrome, Firefox)
- Cho phÃ©p quyá»n truy cáº­p webcam
- Kiá»ƒm tra webcam Ä‘ang Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi app khÃ¡c

### Frame rate tháº¥p

```bash
# Giáº£m JPEG quality trong app_realtime.py
cv2.imencode('.jpg', img, [cv2.IMWRITE_JPEG_QUALITY, 70])  # Tá»« 85 â†’ 70

# Hoáº·c tÄƒng sá»‘ workers
docker-compose scale spark-worker=4
```

---

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

1. **Apache Spark**
   - [Spark RDD Programming Guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)
   - [Spark Cluster Mode Overview](https://spark.apache.org/docs/latest/cluster-overview.html)

2. **MediaPipe**
   - [Selfie Segmentation Guide](https://google.github.io/mediapipe/solutions/selfie_segmentation.html)
   - [MediaPipe Python API](https://google.github.io/mediapipe/getting_started/python.html)

3. **Streamlit WebRTC**
   - [streamlit-webrtc Documentation](https://github.com/whitphx/streamlit-webrtc)
   - [WebRTC Best Practices](https://webrtc.org/getting-started/overview)

4. **Docker**
   - [Docker Compose Reference](https://docs.docker.com/compose/compose-file/)
   - [Docker Networking](https://docs.docker.com/network/)

---

## ğŸ¯ Káº¿t Luáº­n

### ThÃ nh Quáº£ Äáº¡t ÄÆ°á»£c

âœ… XÃ¢y dá»±ng thÃ nh cÃ´ng há»‡ thá»‘ng streaming real-time vá»›i TCP Socket  
âœ… TÃ­ch há»£p Apache Spark Ä‘á»ƒ xá»­ lÃ½ phÃ¢n tÃ¡n video frames  
âœ… Ãp dá»¥ng AI (MediaPipe) vÃ o Big Data pipeline  
âœ… Deploy hoÃ n chá»‰nh vá»›i Docker Compose  
âœ… Äáº¡t yÃªu cáº§u bÃ i táº­p: Stream + Spark + Real-time display  

### BÃ i Há»c Kinh Nghiá»‡m

- **Network Protocol Design**: Thiáº¿t káº¿ TCP protocol vá»›i header/payload chuáº©n
- **Spark RDD**: Hiá»ƒu cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a RDD transformation & action
- **Containerization**: Quáº£n lÃ½ multi-container system vá»›i Docker Compose
- **Real-time Processing**: Xá»­ lÃ½ latency vÃ  throughput trong streaming system



---

<div align="center">

**Made with â¤ï¸ by Tráº§n Nguyá»…n Äá»©c Trung**

*IE212 - Big Data Technologies - UIT 2024-2025*

---

ğŸ“§ **Contact:** 23521687@gm.uit.edu.vn  
ğŸ”— **GitHub:** [Trunguit1122](https://github.com/Trunguit1122)

</div>
